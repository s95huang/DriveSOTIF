# DriveSOTIF: Advancing Perception SOTIF Through Multi-Modal Large Language Models

## Paper
Our preprint is avaliable at https://arxiv.org/abs/2505.07084


## License:
The PeSOTIF and CADC dataset are accessed under CC BY-NC-SA 4.0 license. Proprietary LLMs, such as GPT4, GPT4o, etc. are accessed under their licenses, terms and conditions. Open-source LLM models and LVLM, such as Blip, Blip2, LLAVA, Qwen2-VL, etc., are accessed under their corresponding licenses.


## Citation
```
@misc{huang2025drivesotifadvancingperceptionsotif,
      title={DriveSOTIF: Advancing Perception SOTIF Through Multimodal Large Language Models}, 
      author={Shucheng Huang and Freda Shi and Chen Sun and Jiaming Zhong and Minghao Ning and Yufeng Yang and Yukun Lu and Hong Wang and Amir Khajepour},
      year={2025},
      eprint={2505.07084},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      url={https://arxiv.org/abs/2505.07084}, 
}
```

